id,title,description,image_path,background,artifacts,problem_statement,data_glossary,research,elicitation,interpretation,user_story,workflow,prototype,feedback,reflection
1,Conceptual Model of Instructional Design,"In this project, I and my teammate researched the factors driving competency-based grading in middle school and the need for a taxonomy to interpret state guidelines.",imgs/1_cover.jpg,"As I began my grad school in spring 2025, I joined hands with an educator from Kansas to formulate a research topic for a 600-level course project. The course was ""Advanced Learning Environments Design,""  focused on instructional design and modes of curriculum delivery. It was a two member group project. The focus area for our project was standardizing curriculum definition & grading systems for K-12 across the US. Schools across the US follow different curriculum structures and grading mechanisms set by education boards. This largely depends on the state and the school's district. Interpretations of academic standards and rubric vary vastly. We identified terminologies and real-world objects that are loosely interconnected in real-time and also in the digital system.<p>We intially bounced ideas as shown in the image above. My teammate lamented, from her own experience, how it can be cumbersome to interpret state standards into a measurable outcome.</p>","We utilized the <span style=""font-style: italic;"">Design Thinking for Educators Toolkit</span> by IDEO, as a tool to ideate and reflect throughout the project cycle. The initial phase involved in specifiyng the problem. My teammate as an educator, contributed to detailing the problem statement. We set out to identify the current state of curriculum, particularly in middle school and high school, methods and metrics used by teachers. Also, most schools use Canvas LMS for curriculum management and assessment.","The problem statement is to identify a taxonomy for implementing Curriculum standards that is defined by different States in the US. Competencies can be defined based on a taxonomy. Defining a taxonomy will serve as a template for educators to define their curriculum and translate those standards into Canvas LMS. Also, the current Canvas LMS does not have the option to map to quiz questions to a Criteria. For this project, we focused on Iowa State Standards.","Before elicitation process, we collected a list of terms and descriptions that are present in the real-world and in the system. In Canvas Learning Management System (LMS), an outcome refers to a measurable statement that defines what students should know or be able to do at the end of a learning experience. Outcomes are used to assess student learning and performance, aligning with specific educational standards or learning goals.<p>The real-world objects were vastly different from the objects contained within the system. When the nomenclature is different across spaces, the object map and it's relationships become disconnected. That's the problem we set out to solve.</p><p>Refer to the list of definitions provided by Education Department of Iowa <a href=""https://drive.google.com/viewerng/viewer?url=https://educate.iowa.gov/media/4803/download?inline%3D"" target=""_blank"">Iowa State Guidelines</a></p>","Given the project duration, the research was qualitative and exploratory in nature. My team identified educators, subject matter experts for user interviews. My teammate set to discover insights from her discussions with educators in her circle. I conducted unstructured converstions with an industry expert who specializes in Human Factors and is also an experienced eductor. We utilized IDEO's research prep template as a starter. The selection of interview location was also crucial, as human subjects are comfortable in their natual environment.","We set forth by asking fundamental questions. <ul>
            <li>What metrics are used in your institution to measure competencies of students?</li>
            <li>Who is the responsible for Curriculum definition and where do educators fit in this process?</li>
            <li>To what degree, is the system automated in your organization's delivery process?</li>
            <li>How is the real-world taxonomy of you delivery mechanism is translated into the LMS?</li>
            </ul>
        
            The educators echoed the following themes in our discussions.<ul>
            <li>Curriculum Outcomes are manually aligned to Rubric in the Canvas LMS</li>
            <li>There is no standardized Outcome definition in Canvas LMS across educational institutions</li>
            <li>Lack of transferability between rubrics and different items requires ""creative"" work-arounds by teachers which makes module flow daunting for students</li>
            <li>Rubric are added manually to assignments (assignments, quizzes, discussions)</li>
            </ul>","We identified a recurring theme from the conversations. <ul>
            <li>Instructors would like to spend less time in curriculum creation, defining course outcomes, rubrics </li>
            <li>Only a few educators create their rubrics</li>
            <li>Educators would love someone else to define the outcomes</li>
            <li>Outcomes can be a separate entity and not a child entity of Courses in the LMS</li>
            <li>Question-Criteria mapping is not supported by the system</li>
            </ul>
            Before developing user story maps, and prototypes I identified a possible taxonomic workflow for interpreting broad education standards into an actionable outcome. The example provided in the image considers <span style=""font-style:italic;"">Number Systems</span> for grade 8 mathematics. The real-world objects are identified into discrete units before being interpreted into the system.","After decomposition of tasks, I developed user roles, user activities, user stories for identified tasks. My teammate, as an educator, validated the decomposition. We also sought to verify the requirements with a curriculum coordinator in my teammate's institution. These can be seen as green stickies in the image below.",I created 8-step workflow which curriculum coordinators and instructors can use to create curriculum and course assignments. This is essentially a rubric that can be applied to any course or curriculum. The workflow depicts the steps in a real-world setting and the assimilation of those objects in the Learning Management System.,"The project was conceptual, hence we did not focus on the user interface or user experience in the system. Rather, we sought to identify the workflow, and capture those tasks in the system. I designed a high-fidelity workflow to depict the user-flow.
            <p>Link to the prototype:<a href=""https://drive.google.com/viewerng/viewer?url=https://educate.iowa.gov/media/4803/download?inline%3D"" target=""_blank"">Prototype</a></p>","We gathered feedback on the workflow and the depth of automation. Feedback was provided by a school's curriculum coordinator and a usability expert. Curriculum coordinator liked the idea of weighted average for Outcomes as some criteria might be more meaninful than others. They particularly preferred the idea of the LMS recommending course outcomes rather than the instructor deciding. This reduces manual intervention and cognitive load. Each rubric is customized to assess specific outcomes, which helps instructors and students understand expectations and objectives</p>
            <p>The usability expert provided feedback on the interface prototype, suggesting improvements such as making certain elements more obvious, appropriate labeling, and reducing the amount of white space.</p>
            <iframe src=""https://drive.google.com/file/d/1WUEa23EligLX7KTGuXo5EOJ6BK-Ser-j/preview"" width=""640"" height=""480"" allow=""autoplay""></iframe>","The duration of the semester prevented us from testing the proposed workflow with a larger sample. The mapping of real word objects with the existing system objects is a real-time exercise, and we cannot be certain that curriculum designers will find the workflow any easier. The struggle lies in interpreting the state guidelines and manually creating the taxonomy for various subjects. This will be laborious and time-consuming. Metrics of the workflow also depends on the user experience in the system.
            <p><h3>Poster Style Presentation: <a href=""https://miro.com/app/board/uXjVMCZr5M0=/?moveToWidget=3458764585270731163&cot=14"">Poster</a></p> </h3>"
2,Tractor In-Cab Display,"In this project, I collaborated with four other colleagues to investigate modern farming practices in Ames, Iowa, focusing on the use of technology. The team consisted of a software engineer, civil engineer, industrial engineer, and a HCI professional. Our goal was to examine the existing state and functionality of John Deere's cab displays, as well as the tasks that users perform in their daily routines.",imgs/2_cover.jpg,"The project's objective was to identify a tool or technological function, identify areas for improvement, and propose new interface solutions. During the brainstorming phase, a teammate with a background in agricultural studies suggested exploring electronic displays used in agricultural machines. Given her previous experience at ISU's research farm and potential access to machinery and display simulators for research, we decided to proceed with this idea. Also, there was a potential for a large sample of participants, as farming is one of the prevalent occupations.<p> The motivation behind this study was to comprehend how farmhands, farmers, and agriculturalists interact with John Deere's machines and the environment in which they work. The age range of end-users varies from 17 to 70, and each person's mental model and technical proficiency are expected to vary significantly. The output of the project in a way could lead to task improvements, optimal interactions, and reduced frustrations. The image below was created by one of my teammates to decompose the existing workflow.</p>","The project duration was between February and April of 2024, and there were no significant farming practices due to harsh weather and soil conditions. With limited opportunities for field research, our team chose to work with cab simulators at one of Iowa State's student labs and also utilized John Deere's simulator website. The team utilized John Deere's CommandArm Simulators for understanding the current state of the interface, and the workflow. 4600 CommandCenter & 4640 Universal Displays were utilized for the course of the project. Though different generations of displays exist, core application settings, and system settings are similar. Machine settings will vary based on the type of machine (tractor, cotton harvester, sprayer, etc.).<p>Link to Display simulator: <a href=""https://displaysimulator.deere.com/"">CommandArm Simulator</a></p>","Before identifying the problem statement, my team set out to explore the current state of John Deere's cab displays. Each of us identified a key focus area in the system and decomposed tasks using <span style=""font-style:italic;"">Hierarchical Task Analysis (HTA)</span>. This prevented us from assuming the problem statement and withdrew the temptation to identify usability issues without interacting with the users. Upon initial analysis of the user interface and workflows, we identified prevalent factors.<ul>
            <li>The user interface had large buttons, and high visual contrast</li>
            <li>The scroll bar did not have a slider; instead, it used up and down arrows.</li>
            <li>Not a prominent use of dropdowns and multi-select checkboxes.</li>
            <li>Task reversals were accomplished by clicking on ""close"" buttons instead of using the back button.</li>
            </ul> 
<p>There were a few more observations, but one of the reasons for such a design could be to adhere to WCAG guidelines for visual contrast and the need for a simple dialog format. Also, the users will use the display mostly with their dominant hand, as they drive the machine on the farm. It is essential that buttons are visible enough with legible text even under the sunlight. So, providing a sleek, modern UI may not be best suited. Though different approaches to user experience need to be tested, given the timeline of the project, we focused on improving the learnability, natural mapping of different functions, minimizing cognitive energy for performing tasks, and error prevention rather than UI.</p>","After experimenting with the simulator on John Deere's website and in the student lab, I collaborated with my teammates to identify the essential data glossary and their relationships at a high level. I then created a simple definition of cards on Miro, as shown below.","For the requirements elicitation and user discussion, we identified three participants with varying levels of farming experience, which added more variability to the data. The participants were randomly selected through mutual contacts, and none of them were familiar to the team.The user research plan included: 
<ul>
<li> Elicitation workflow</li>
<li>Inquiry of participants as they perform specific tasks</li>
<li>Unstructured and structured interview</li>
<li> Questionnaires on 5 point-likert scale</li></ul>","On a fine, warm day, my team and I visited the participants for elicitation activities. We split into groups of two to interview each participant. Before initiating discussions, the participants <strong>consented</strong> to the interview, and we acknowledged our <strong>positionality</strong>; as the participants had more expertise and technical know-how. This established a good rapport with the participants, and the discussion started with a questionnaire on the following: 
<ul>
<li>PII on age, occupation</li> 
<li>Type of agricultural equipment used</li>
<li>Average use of the interface per session (measured in hours)</li>
<li>Frequency of display's usage in a year (descriptive)</li>
<li>Types of tasks performed (planting, tilling, bailing, etc.)</li>
<li> Usability rating of the interface on a scale of 1-5</li>
<li>Open-ended question on issues in the system</li>
</ul> 

The participants explained the general tasks often performed in the field during harvesting and tilling operations. They were asked to provide a walkthrough of three specific functions that were identified during the discussions: (a) resetting tillage depth value and resetting the field map of the machine, (b) adding an implement of a different brand, and (c) customizing the main page layout of the display. The discussion lasted approximately 60 minutes, during which I took notes and participated in the discussions. <p>Based on observations and information gleaned from the user discussion, recurring themes in user statements were identified. After consultations with the team, I grouped all observations based on different themes and categorized those themes into affinity maps. Connections between themes were identified and the team validated the categories. ","Participants found it difficult to customize the display, expressing a desire for more straightforward navigation to customization settings. One participant quipped, <em> ""Customization is deep into settings""</em>. They also mentioned the hassle of manually adding tools and adjusting dimensions and settings for custom-made and third-party tools. Inexperienced and experienced users emphasized the frustration of learning tractor interfaces, highlighting the need for better user education. So our next step was to improve the <em>dialiog initiative</em>, <em>customizability</em>, and <em>learnability</em> of the system. 

<p>After brainstorming with my teammates, I created an activity diagram outlining a potential workflow for customizing display page layouts. We defined the scope of the project to focus on designing the following tasks:
<ul>
<li>Re-design of layout manager and customization</li>
<li>Improving the current state of help documentation</li>
<li>Creating, customizing, & saving an Implement profile</li>
<li>Redesign of the field map and its mapping visualization</li>
</ul>

Participants reiterated that accessing help documentation in the display was cumbersome and was not intuitive. ",User persona created by a teammate.,"After gathering and synthesizing requirements from the elicitation process, I created a couple of low-fidelity sketches to customize the ""run page sets"" and illustrate potential user flows. My other teammates worked on improving the user experience of the help documentation, and field map, and adding Implements to John Deere's machine. Our goal was to reduce the number of clicks required for users while working on display during farming activities and enhance the system's ease of use. Another focus was to redesign the natural mappings of functions. 

<p>The team conducted a non-user expert evaluation study using the following <strong>heuristics principles</strong>:
<ul>
<li>Readability</li>
<li>Learnability</li>
<li>Minimizing memory load</li>
<li>Prevent Errors</li>
<li>Consistency</li>
</ul>

Based on the Usability Issues severity scale (Adapted from Wilson, 1999), we identified the severity of the expert feedback and implemented changes to workflow. ","Due to time constraints on the project, we have revised the scope to focus on improving (a) the customization of the run page set and (b) the help documentation. I created hi-fidelity prototypes for customizing page layouts, and also an animation feature for the help documentation. It should be noted that, we did not focus on the visual system and interface of the display. Here is a video walk-through: 
<p><iframe src=""https://drive.google.com/file/d/1Z6NkhNedL5h2JzDgxR8v9tb-viLid1Px/preview"" width=""640"" height=""480"" allow=""autoplay""></iframe></p>
<p>Link to the prototype:<a href=""https://www.figma.com/proto/hhK9WqnLJGa9ghMIEYGAni/Tractor-Cab-Display?page-id=0%3A1&node-id=642-7455&viewport=102%2C501%2C0.02&t=pcDmVFuoOLx7gHL0-1&scaling=scale-down&starting-point-node-id=642%3A7455"">Prototype</a></p>","We conducted a <strong>within-subjects</strong> experiment, testing two interface designs (independent variable), and carefully controlling the variables to ensure accuracy and fairness. Each participant was assigned one of the two designs, which allowed us to compare the impact of different interfaces on the results. In addition, we randomized the order of the tasks to minimize any potential bias on performance. This randomization method was highly effective, ensuring that any effects were evenly distributed across all participants, reducing the likelihood of errors affecting the experiment's outcome. For the final experiment, participants tested the following tasks:
<ul>
<li>Customization of the tractor's in-cab display dashboard</li>
<li>Learnability of a specific function in the display by using the help guide and its features</li>
</ul>

<p>The experiment was randomized to reduce the effect of confounding variables and biases. The users were tested in a lab setting with the prototype loaded into the display. Participants tested the current and proposed design. The team split into to teams of two to observe the participants. A <strong>T-test</strong> was conducted for the baseline system and the proposed design, with the independent variable being the interface version. The data are represented using grouped bar charts to compare two data sets for each metric. Based on NASA TLX (NASA, 1986), metrics on (a) mental demand, (b) physical demand, (c) temporal demand, (d) frustration, (e) performance, and (f) effort were collected. Satisfaction and frustration were also collected on a 5-point Likert Scale. Comparing the means of user metrics highlighted user preference between the baseline and the proposed system. Open-ended questions were used to collect post-trial feedback to identify themes and pain points after each trial. The below chart depicts the <em> dependent variable</em>, data type, data collection method, and frequency of data collection.</p>

<h4>Statistical Analysis</h4><p>For the dashboard customization task, the NASA TLX demonstrated notable improvements in the proposed design across several domains. Mental demand decreased from a mean of 7.3 to 4.3, suggesting that the redesigned interface requires less cognitive effort, possibly due to a more logical arrangement of information or more straightforward navigation paths. Physical and temporal demand also saw reductions, indicating an interface that is less physically taxing and more efficient, allowing users to complete tasks faster. Although performance decreased slightly, this might highlight areas where the new interface could be optimized further. The effort required significantly decreased, reflecting an overall enhancement in usability and ease of interaction. Frustration levels saw little change, suggesting that while the redesign addresses many usability issues, some elements contributing to user frustration may still need attention. The 5-Point Likert Scale results correlate with the findings from the TLX, where user satisfaction improved in the proposed design, moving from a mean of 3.7 to 4.3. This improvement signifies a more positive user perception of the interface's ability to meet their needs effectively. Furthermore, a decrease in user-reported frustration supports the notion that the proposed interface mitigates factors that previously led to user dissatisfaction. 

<p>In the Help Center task, the NASA TLX results reflected substantial enhancements with the proposed interface. The mental demand saw a significant drop, indicating that the redesigned help center is more straightforward and easier to navigate, likely due to better-organized content and clearer guidance. Physical demand decreased as well, which could be due to improved accessibility of help functions or more intuitively placed controls. Temporal demand remained stable, suggesting that while the interface is easier to use, the intrinsic complexity of help tasks maintains the time needed for completion. Likert Scale results from the Help Center task showed a dramatic increase in user satisfaction, moving from a mean of 2.0 to 4.3, which underscores a strong user preference for the redesigned interface. This is a clear indicator that the improvements made in the help center are effectively enhancing user experience</p>","The statistical power of the project is questionable because a larger sample size is needed. The visual system was not addressed in this project. Redesigning the user experience and visual system may yield different results. The interface was tested on an iPad in a controlled environment. Therefore, the observed results may differ from a real-world inquiry."
3,Design of Ames Public Library Website,"During the summer of 2024, as a frequent visitor of the Ames Public Library, I contacted the library director to offer my contribution to the community and work on improving systems for human interaction. After several discussions, I decided to focus on enhancing the user experience of the library's website. ",imgs/3_cover.jpg,"During the summer of 2024, I frequently visited the public library in Ames. I spent most of my time reading books on art and design. I used the Ames Public Library website to browse book titles, place holds, and look up daily events. As I became a frequent user of the system, I became fascinated by the library management system, the relationship between objects, and how the entire system works for both library users and staff. I explored different library management systems used by libraries in the US and how they utilize third-party vendors for managing their content. The Ames library has both a legacy website and a revamped website designed around 2020, and a third-party vendor manages the library management system. The website provides general information about library events, book sales, and more.
<p>I made note of areas for improvement in the current workflow as a user and as a designer. I observed noticeable and confusing issues related to grouping of objects, unnecessary clicks, redundant workflows, and visual contrasts. After mapping out the workflow of the current system, I focused on analyzing areas for improvement and eliminating redundant user flows.<p>","Instead of relying on traditional design practices, I used <strong>Sophia Prater's Object Oriented UX</strong> for the project. This concept was developed by Sophia in 2015. The model is similar to entities and relationships between entities in a database. After learning about this process from a UX meetup in Des Moines, I realized that this process could help me in understanding the complex array of objects on the Ames Public Library's website and demystify the connections between different entities. The image below shows the process of ORCA. ","While I noticed significant usability issues in the system, I wanted to avoid confirmation bias. Therefore, I prepared my research to speak with regular users and understand their perspectives. The library demography can be categorized into five groups.
<ul>
<li>Kids</li>
<li>Yound Adults</li>
<li>Adults/Resident</li>
<li>New Residents</li>
<li>ISU Students</li>
</ul>
<p>Upon intial analysis of the system, following observations were made<p>
<ul>
<li>Visual contrast between ui elements can be enhanced, and there by increasing scannability for the user</li>
<li>Natural grouping of objects and attributes were found to be missing from workflows</li>
<li>Concise information is not obvious to the user. Accordions may not be needed</li>
<li>Color and typography needs to be checked for WCAG standards</li>
</ul>
","The strategy involves using Object-Oriented UX to identify and group nouns as objects, their core content, sub-objects, and attributes, which will then be organized and displayed on a webpage. I scoured for real-world objects from conversations with people, common library-speak, and also in the existing system. The object must be a noun, place, content-type or a thing. ","The research was exploratory, and due to time constraints, I did not have a large sample size. I had discussions with adult users and some young adults.The interviews were unstructured because I believed that structured discussions would hinder my understanding of the users' mental model. I identified two frequent users of the library and set up a time to meet in their environment. Each meeting lasted an hour, during which I took field notes in my journal.","August 2024: On a warm afternoon, I visited the office of the adult participant to elicit her thoughts and ideas. Having completed her mid-day work, the adult participant sat down to spend some time with me. She explained her perspective and knowledge on how the library, space, staff, people, and the website all work together as a system. I acknowledged my positionality as she had more knowledge about the workings of the library. She also used to work for the library a few years ago. During the discussion with the participants, I posited some of following questions:
<ul>
<li>How often do you spend time at the library?</li>
<li>What is your favourite genre of books?</li>
<li>How frequently do you set aside time to read books each week?</li>
<li> What is your thought process when you decide to search for a particular kind of book?</li>
<li>Do you focus on specific categories that relate to our lives?</li>
<li>How long does it take for you to find your preferred book at the library?</li>
<li>Do you think there could be ways to narrow down your research and decisions in spite of your schedule?</li>
<li>Do you prefer to spend time there or read it at home?</li>
<li>Can you walk me through the process of placing holds on the webpage?</li>
</ul>
<p>The participants appeared to be more at ease with the casual and conversational format. The discussion also involved passive contextual inquiry.","I analyzed the statements made by both participants to identify underlying needs and concerns. The adult participant's choice of books or any material from the library is driven by the <em>""lyrical quality""</em> and the visuals of the book cover. She mentioned that some of the functions on the current website are not obvious to her, and she needs to navigate between different functions to understand them.One example she provided was to reduce the use of accordions in styles and make information more evident as the user scrolls down a page. The adult participant also mentioned her active role in community events and her drive to help marginalized people. In the existing system, it can be difficult to skim the event calendar and decipher events for a specific day. Additionally, people with ADHD can find it challenging to sift through the required information. I, myself found it quite stressful with a wall of texts and emphasis. 

<p>The young adult mentioned that it would be easier for her to find different series of the same book quickly and place holds in succession. While I didn't design the vendor's library management system, I did create workflows for book collections segmented by age demographics. Based on themes I discovered and my usability analysis of the website, I identified core objects, core content, metadata, and relationships between different objects. I used the ORCA process to decode the relationship, as can be seen from the images.</p>","Objects were placed and nested based on their affinity, function, and purpose. For example, in the current system <em>Meeting and Study Rooms</em> were mapped under <em>Events and News</em>. For instance, I defined the meeting and study rooms as separate entities to ensure that users interested in viewing only the events can have a clearer and easier way of understanding the emphasis. This also mimics the real-world reservation of meeting rooms, where people would walk over to the help desk and reserve a room.","A usability study based on heuristics was conducted by a usability expert. After gathering feedback, high-fidelity prototypes was created based on sketch 1. Due to time constraints, I was unable to sketch alternate workflows. ","Based on feedback from the usability expert, I created a hi-fidelity prototype. <iframe style=""border: 1px solid rgba(0, 0, 0, 0.1);"" width=""800"" height=""450"" src=""https://embed.figma.com/proto/zryQv2SgpzFTg1lZKZKbii/Project?page-id=67%3A489&node-id=600-15818&node-type=canvas&viewport=527%2C526%2C0.06&scaling=min-zoom&content-scaling=fixed&starting-point-node-id=600%3A15502&embed-host=share"" allowfullscreen></iframe>",Users tested the learnability and synthesizability of the prototype. ,"A larger sample size, and more alternate workflows are needed for future tests."
4,Self Data Portrait,This project shows my self-data portrait using Processing library.,imgs/4_cover.jpg,"During the fall of 2024, I created art forms through <strong>Processing</strong>. This was part of the <em>Data, Code, Form</em>  graduate course. The course was an art class with an emphasis on procedural knowledge and procedural programming. Processing is a Java library artists use to create art forms and represent data points through code. This project focuses on representing my data and creating a self-portrait using my information. I was inspired by <a href=""https://giorgialupi.com//"" class = ""special-link""  target = ""_blank"">Giorgia Lupi's</a> dear-data project and her thoughts on humanizing data. This is also my first experience with Java programming, and learning code visually has truly encouraged me to think procedurally. I wish I had stumbled upon this sooner! 

<p>My initial idea was to represent personal traits such as personality, skills, habits, or even my grocery bills over the last three months in meaningful forms.  The idea is to represent data points that depict a picture of me in a humanizing, and inspiring way. I've always thought of data in discrete terms, but what if there is a way beyond numbers and line graphs?  I decided to find meaning in my solo travels. I created a canvas showcasing three places I have traveled to, inviting the user to enter each house for further exploration. The landscape canvas features a night mode that can be activated by clicking on the sun object. Each location is explored through a carousel of images, which includes timestamps and descriptive text. I plan to enhance this project by visually representing distance, vehicular speed, and commute time as data points. The location history data can be downloaded from Google Maps. I will soon post a video demonstrating this.</p> ",,,,,,,,,,,
5,Instructional Design Case Analysis,A case analysis of Instructional Design,imgs/5_cover.jpg,"Professor Peg Ertmer of Purdue University specializes in learning design and technology. She authored the <em>ID Casebook: Case Studies In Instructional Design</em>. The book contains open-ended cases that encourage designers to solve real-world problems. This case study was conducted for a 600-level graduate course called <em>Advanced Learning Environments</em>. I explored the use case of managing scope change in an instructional design project within the corporate context. Jack Waterkamp navigates product development and instructional design amidst stakeholder and development crises. In the study, I have detailed the problem statement, the root causes for design delays, and potential solutions depicted in the form of an Issue-Based Information system. <iframe class=""pdf"" src=""https://drive.google.com/file/d/1iKBBDd0qR0UqN2QFZ19dgpCoUS9iGRJG/preview"" width=""800"" height=""500""></iframe> 
",Artifact text 5,,,,,,,,,,
